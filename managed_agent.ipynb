{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eccfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool, GradioUI, LiteLLMModel\n",
    "from smolagents.utils import encode_image_base64, make_image_url\n",
    "import yaml\n",
    "#from Gradio_UI import GradioUI\n",
    "from langchain_ollama import ChatOllama\n",
    "from tools.final_answer import FinalAnswerTool\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load prompts from YAML file\n",
    "with open(\"prompts.yaml\", 'r') as stream:\n",
    "    prompt_templates = yaml.safe_load(stream)\n",
    "\n",
    "# Get the system prompt from the YAML file\n",
    "system_prompt = prompt_templates[\"system_prompt\"]\n",
    "\n",
    "search_tool = DuckDuckGoSearchTool()\n",
    "\n",
    "search_model_name = 'granite3.3:latest'\n",
    "search_model = LiteLLMModel(model_id=f'ollama_chat/{search_model_name}')\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "    model=search_model,\n",
    "    tools=[search_tool],\n",
    "    max_steps=6,\n",
    "    verbosity_level=1,\n",
    "    grammar=None,\n",
    "    planning_interval=None,\n",
    "    name=\"web_agent\",\n",
    "    description=\"Browses the web to find information.  Only works with textual information\",\n",
    "    prompt_templates=prompt_templates\n",
    ")\n",
    "\n",
    "react_model_name = 'cogito:14b'\n",
    "# Initialize the chat model\n",
    "react_model = LiteLLMModel(model_id=f'ollama_chat/{react_model_name}')\n",
    "final_answer = FinalAnswerTool()\n",
    "\n",
    "def check_reasoning(final_answer, agent_memory):\n",
    "    model_name = 'cogito:14b'\n",
    "    multimodal_model = LiteLLMModel(model_id=f'ollama_chat/{model_name}')\n",
    "    prompt = f\"\"\"\n",
    "        Here is a user-given task and the agent steps: {agent_memory.get_succinct_steps()}. Now here is the answer that was given: \n",
    "        {final_answer}\n",
    "        Please check that the reasoning process and results are correct: do they correctly answer the given task?\n",
    "        First list reasons why yes/no, then write your final decision: PASS in caps lock if it is satisfactory, FAIL if it is not.\n",
    "        Don't be harsh: if the result mostly solves the task, it should pass.\n",
    "        \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": prompt,\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    output = multimodal_model(messages).content\n",
    "    print(\"Feedback: \", output)\n",
    "    if \"FAIL\" in output:\n",
    "        raise Exception(output)\n",
    "    return True\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    model=react_model,\n",
    "    tools=[final_answer],\n",
    "    managed_agents=[web_agent],\n",
    "    additional_authorized_imports=[\n",
    "        \"geopandas\",\n",
    "        \"plotly\",\n",
    "        \"shapely\",\n",
    "        \"json\",\n",
    "        \"pandas\",\n",
    "        \"numpy\",\n",
    "    ],\n",
    "    max_steps=6,\n",
    "    verbosity_level=1,\n",
    "    planning_interval=None,\n",
    "    name=\"Manager\",\n",
    "    description=\"The manager of the team, responsible for overseeing and guiding the team's work.\",\n",
    "    final_answer_checks=[check_reasoning],\n",
    "    prompt_templates=prompt_templates\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37caee",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1925d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent.run(\"How many r's are in the word Strawberry?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb53c596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "image_urls = [\n",
    "    \"https://as1.ftcdn.net/jpg/00/83/40/34/1000_F_83403431_smNEvB5iYrCV7R3zB8SKJ7xRFfJ5JMD2.webp\", \n",
    "]\n",
    "\n",
    "images = []\n",
    "for url in image_urls:\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\" \n",
    "    }\n",
    "    response = requests.get(url,headers=headers)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa4b19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_agent.run(\n",
    "    \"\"\"\n",
    "    How many cats are in this picture?\n",
    "    \"\"\",\n",
    "    images=images\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
